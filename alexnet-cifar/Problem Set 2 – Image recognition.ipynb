{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we have briefly reviewed the idea of learning good features directly from data and went through the concept of convolutional neural networks along with few architectures.\n",
    "\n",
    "Until recently, building convolutional neural networks was tough. There was no high-level tools for that, you would be required to understand all the internal mechanics of the model and its operations.\n",
    "\n",
    "Today, due to the high-level tools such as Keras and TensorFlow, everybody can build a convolutional neural network and put it to work without diving deep into them. What used to be a one-month project became a few hours exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.backend import tf as ktf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = pickle.load(open('data/train_set_all.pkl', 'rb'))\n",
    "cv_images, cv_labels = pickle.load(open('data/test_set_all.pkl', 'rb'))\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np_utils.to_categorical(np.array(train_labels), 10)\n",
    "\n",
    "cv_images = np.array(cv_images)\n",
    "cv_labels = np_utils.to_categorical(np.array(cv_labels), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(cv_images.shape)\n",
    "print(len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(np_array):\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.imshow(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(data_set, labels, example_index):\n",
    "    show_image(data_set[example_index])\n",
    "    print('Label: ', labels[example_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(train_images, train_labels, example_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(cv_images, cv_labels, example_index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2012 a convolutional neural network called AlexNet won ImageNet competition. \n",
    "\n",
    "Go through an [original AlexNet paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) to investigate the architecture. Next, investigate the [basics of Keras](https://keras.io/#keras-the-python-deep-learning-library). We will use it with TensorFlow backend.\n",
    "\n",
    "You are also encouraged to go through some CNN tutorial for Keras. There is a number of them online (for example, [this](https://elitedatascience.com/keras-tutorial-deep-learning-in-python) or [this](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)).\n",
    "Now, build AlexNex network with Keras for object recognition. Note that standard AlexNet works with 224x224 input images. The dataset you are going to use for this problem is 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_15 (Lambda)           (None, 54, 54, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 14, 14, 48)        3648      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 7, 7, 64)          76864     \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 7, 7, 96)          55392     \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 7, 7, 96)          83040     \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 7, 7, 64)          55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 490,378\n",
      "Trainable params: 490,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Layer 0\n",
    "# resize images to have the same input as in the AlexNet\n",
    "model.add(Lambda(lambda image: ktf.image.resize_images(image, (54, 54)), input_shape=(32,32,3)))\n",
    "\n",
    "# AlexNet layers description here: https://sushscience.wordpress.com/2016/12/04/understanding-alexnet/\n",
    "# Keras layers docs: https://keras.io/layers/core/\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), strides=4, activation='relu', padding='same'))\n",
    "\n",
    "# Layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 3\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 5\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 6\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "# Layer 7\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "# Layer 8\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use training set for training the network to recognize objects. You might want to use RMSProp optimizer to speed up the training.\n",
    "\n",
    "Convolutional networks require a lot of computing power for training. Typical setup for training CNN is to use GPU, however, in this problem you are not required to do so. CPU will be fine as well.\n",
    "\n",
    "If you are using CPU for this subproblem, training process might be slow. You can stop it manually as soon as you get meaningful results.\n",
    "\n",
    "Report the results on the training and cross-validation sets. The report should contain the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.7868 - acc: 0.3688 - val_loss: 1.6963 - val_acc: 0.3892\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 1.4104 - acc: 0.4937 - val_loss: 1.3685 - val_acc: 0.5194\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.2765 - acc: 0.5459 - val_loss: 1.2295 - val_acc: 0.5549\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.1986 - acc: 0.5715 - val_loss: 1.2725 - val_acc: 0.5506\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.1340 - acc: 0.5957 - val_loss: 1.1865 - val_acc: 0.5838\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.0798 - acc: 0.6158 - val_loss: 1.1829 - val_acc: 0.5864\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.0261 - acc: 0.6343 - val_loss: 1.1991 - val_acc: 0.5808\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.9908 - acc: 0.6485 - val_loss: 1.1960 - val_acc: 0.5904\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.9479 - acc: 0.6631 - val_loss: 1.1582 - val_acc: 0.5977\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.9167 - acc: 0.6755 - val_loss: 1.1734 - val_acc: 0.5940\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.8840 - acc: 0.6899 - val_loss: 1.2165 - val_acc: 0.6001\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.8446 - acc: 0.7002 - val_loss: 1.1952 - val_acc: 0.6070\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.8143 - acc: 0.7113 - val_loss: 1.2288 - val_acc: 0.5981\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.7849 - acc: 0.7215 - val_loss: 1.2319 - val_acc: 0.6112\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.7411 - acc: 0.7373 - val_loss: 1.2591 - val_acc: 0.6022\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.7154 - acc: 0.7463 - val_loss: 1.2570 - val_acc: 0.6088\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6942 - acc: 0.7543 - val_loss: 1.2788 - val_acc: 0.6028\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.6657 - acc: 0.7642 - val_loss: 1.3352 - val_acc: 0.5930\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6439 - acc: 0.7739 - val_loss: 1.3239 - val_acc: 0.6087\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6140 - acc: 0.7839 - val_loss: 1.3722 - val_acc: 0.6207\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.6047 - acc: 0.7872 - val_loss: 1.3294 - val_acc: 0.6077\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5865 - acc: 0.7944 - val_loss: 1.3903 - val_acc: 0.6043\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5565 - acc: 0.8051 - val_loss: 1.4617 - val_acc: 0.6058\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5332 - acc: 0.8117 - val_loss: 1.4099 - val_acc: 0.6060\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.5252 - acc: 0.8177 - val_loss: 1.5398 - val_acc: 0.5980\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5106 - acc: 0.8232 - val_loss: 1.5705 - val_acc: 0.6035\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4768 - acc: 0.8350 - val_loss: 1.5479 - val_acc: 0.6087\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4732 - acc: 0.8381 - val_loss: 1.5034 - val_acc: 0.6014\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4664 - acc: 0.8401 - val_loss: 1.5510 - val_acc: 0.6029\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4418 - acc: 0.8511 - val_loss: 1.6321 - val_acc: 0.6005\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4299 - acc: 0.8543 - val_loss: 1.6700 - val_acc: 0.6067\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4278 - acc: 0.8552 - val_loss: 1.7123 - val_acc: 0.6050\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4131 - acc: 0.8608 - val_loss: 1.6242 - val_acc: 0.6167\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4020 - acc: 0.8639 - val_loss: 1.6731 - val_acc: 0.6037\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3999 - acc: 0.8691 - val_loss: 1.7210 - val_acc: 0.6050\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3891 - acc: 0.8696 - val_loss: 1.8242 - val_acc: 0.5979\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3742 - acc: 0.8762 - val_loss: 1.7662 - val_acc: 0.6093\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3542 - acc: 0.8831 - val_loss: 1.7936 - val_acc: 0.6024\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3609 - acc: 0.8826 - val_loss: 1.8136 - val_acc: 0.6052\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.3422 - acc: 0.8881 - val_loss: 1.8863 - val_acc: 0.5957\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3380 - acc: 0.8910 - val_loss: 1.8735 - val_acc: 0.5921\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3402 - acc: 0.8912 - val_loss: 1.9132 - val_acc: 0.6034\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3330 - acc: 0.8930 - val_loss: 1.9851 - val_acc: 0.6074\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3108 - acc: 0.8998 - val_loss: 1.8877 - val_acc: 0.6074\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3145 - acc: 0.8990 - val_loss: 1.9264 - val_acc: 0.6098\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.2997 - acc: 0.9062 - val_loss: 2.1139 - val_acc: 0.6066\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2964 - acc: 0.9062 - val_loss: 1.9432 - val_acc: 0.6137\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3115 - acc: 0.9037 - val_loss: 2.0118 - val_acc: 0.5954\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.2692 - acc: 0.9155 - val_loss: 2.0528 - val_acc: 0.6040\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.3008 - acc: 0.9047 - val_loss: 1.9604 - val_acc: 0.6010\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.2809 - acc: 0.9122 - val_loss: 2.0153 - val_acc: 0.6060\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.2829 - acc: 0.9128 - val_loss: 1.9610 - val_acc: 0.5939\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.2774 - acc: 0.9149 - val_loss: 2.1240 - val_acc: 0.6039\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.2784 - acc: 0.9163 - val_loss: 2.0057 - val_acc: 0.6077\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2657 - acc: 0.9187 - val_loss: 2.0910 - val_acc: 0.6108\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2653 - acc: 0.9198 - val_loss: 2.1895 - val_acc: 0.6091\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2568 - acc: 0.9231 - val_loss: 2.1164 - val_acc: 0.6080\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2725 - acc: 0.9198 - val_loss: 2.0943 - val_acc: 0.5997\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2710 - acc: 0.9191 - val_loss: 2.0351 - val_acc: 0.6064\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2485 - acc: 0.9255 - val_loss: 2.1377 - val_acc: 0.5988\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2480 - acc: 0.9280 - val_loss: 2.2210 - val_acc: 0.6005\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2517 - acc: 0.9265 - val_loss: 2.1621 - val_acc: 0.6025\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2463 - acc: 0.9280 - val_loss: 2.1536 - val_acc: 0.5987\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2693 - acc: 0.9228 - val_loss: 2.0605 - val_acc: 0.6079\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2677 - acc: 0.9225 - val_loss: 2.0601 - val_acc: 0.6023\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2357 - acc: 0.9319 - val_loss: 2.2497 - val_acc: 0.5945\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2243 - acc: 0.9343 - val_loss: 2.1924 - val_acc: 0.5991\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2558 - acc: 0.9265 - val_loss: 2.4265 - val_acc: 0.6037\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2314 - acc: 0.9345 - val_loss: 2.2871 - val_acc: 0.6073\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2506 - acc: 0.9292 - val_loss: 2.3680 - val_acc: 0.6063\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2863 - acc: 0.9207 - val_loss: 2.0897 - val_acc: 0.6024\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2170 - acc: 0.9384 - val_loss: 2.2786 - val_acc: 0.6007\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2430 - acc: 0.9327 - val_loss: 2.4095 - val_acc: 0.6007\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2594 - acc: 0.9297 - val_loss: 2.3753 - val_acc: 0.5963\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2445 - acc: 0.9319 - val_loss: 2.2502 - val_acc: 0.6047\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.2285 - acc: 0.9371 - val_loss: 2.3155 - val_acc: 0.5980\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2381 - acc: 0.9339 - val_loss: 2.3148 - val_acc: 0.5934\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2617 - acc: 0.9297 - val_loss: 2.3705 - val_acc: 0.6135\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2388 - acc: 0.9341 - val_loss: 2.3688 - val_acc: 0.6054\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2507 - acc: 0.9306 - val_loss: 2.4506 - val_acc: 0.6013\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.3097 - acc: 0.9183 - val_loss: 2.3208 - val_acc: 0.6109\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.3464 - acc: 0.9059 - val_loss: 2.1392 - val_acc: 0.6101\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2039 - acc: 0.9427 - val_loss: 2.2995 - val_acc: 0.6009\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2790 - acc: 0.9269 - val_loss: 2.1493 - val_acc: 0.6015\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.2691 - acc: 0.9280 - val_loss: 2.0202 - val_acc: 0.5945\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2447 - acc: 0.9359 - val_loss: 2.3869 - val_acc: 0.6085\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.3632 - acc: 0.9025 - val_loss: 1.7606 - val_acc: 0.5280\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3240 - acc: 0.9143 - val_loss: 2.4283 - val_acc: 0.5985\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2096 - acc: 0.9448 - val_loss: 2.4281 - val_acc: 0.5947\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2631 - acc: 0.9318 - val_loss: 2.4900 - val_acc: 0.6067\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2664 - acc: 0.9311 - val_loss: 2.3980 - val_acc: 0.5948\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.3043 - acc: 0.9215 - val_loss: 1.7702 - val_acc: 0.4909\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4088 - acc: 0.8844 - val_loss: 2.0638 - val_acc: 0.6022\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.3091 - acc: 0.9164 - val_loss: 2.2508 - val_acc: 0.6024\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2022 - acc: 0.9451 - val_loss: 2.3222 - val_acc: 0.6081\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1924 - acc: 0.9498 - val_loss: 2.4049 - val_acc: 0.5991\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.3264 - acc: 0.9165 - val_loss: 2.5635 - val_acc: 0.6022\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.3805 - acc: 0.9030 - val_loss: 2.3789 - val_acc: 0.6001\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2426 - acc: 0.9381 - val_loss: 2.6128 - val_acc: 0.6024\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2724 - acc: 0.9307 - val_loss: 2.5051 - val_acc: 0.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x149c24438>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=64, epochs=100, initial_epoch=0, verbose=1, validation_data=(cv_images, cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load models: https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_name + \".h5\")\n",
    "    print('Saved', model_name, 'to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The best accuracy on the test set is 0.6167 (epoch 33)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, AlexNet does not work very well on such a small dataset. Recall what you have learned from this class to improve its performance. You can also take a look at the [Dropout technique](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) and its [implementation in Keras](https://keras.io/layers/core/#dropout). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_20 (Lambda)           (None, 54, 54, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 14, 14, 48)        3648      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 7, 7, 64)          76864     \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 7, 7, 96)          55392     \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 7, 7, 96)          83040     \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 7, 7, 64)          55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 490,378\n",
      "Trainable params: 490,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dropout_model = Sequential()\n",
    "\n",
    "# Layer 0\n",
    "# resize images to have the same input as in the AlexNet\n",
    "dropout_model.add(Lambda(lambda image: ktf.image.resize_images(image, (54, 54)), input_shape=(32,32,3)))\n",
    "\n",
    "# AlexNet layers description here: https://sushscience.wordpress.com/2016/12/04/understanding-alexnet/\n",
    "# Keras layers docs: https://keras.io/layers/core/\n",
    "\n",
    "# Layer 1\n",
    "dropout_model.add(Conv2D(filters=48, kernel_size=(5,5), strides=4, activation='relu', padding='same'))\n",
    "\n",
    "# Layer 2\n",
    "dropout_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "dropout_model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 3\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "dropout_model.add(Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 4\n",
    "dropout_model.add(Conv2D(filters=96, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 5\n",
    "dropout_model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "# Layer 6\n",
    "dropout_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "dropout_model.add(Flatten())\n",
    "dropout_model.add(Dense(256, activation = 'relu'))\n",
    "# dropout_model.add(Dropout(0.2))\n",
    "\n",
    "# Layer 7\n",
    "dropout_model.add(Dense(256, activation = 'relu'))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "\n",
    "# Layer 8\n",
    "dropout_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "print(dropout_model.summary())\n",
    "\n",
    "dropout_model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.7930 - acc: 0.3617 - val_loss: 1.4552 - val_acc: 0.4692\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.4343 - acc: 0.4839 - val_loss: 1.3932 - val_acc: 0.4884\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.3213 - acc: 0.5272 - val_loss: 1.3251 - val_acc: 0.5292\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.2534 - acc: 0.5543 - val_loss: 1.2263 - val_acc: 0.5595\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1836 - acc: 0.5794 - val_loss: 1.2149 - val_acc: 0.5679\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.1372 - acc: 0.5971 - val_loss: 1.1677 - val_acc: 0.5844\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.0961 - acc: 0.6109 - val_loss: 1.1771 - val_acc: 0.5885\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.0576 - acc: 0.6266 - val_loss: 1.2161 - val_acc: 0.5759\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.0282 - acc: 0.6373 - val_loss: 1.1749 - val_acc: 0.5901\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.9877 - acc: 0.6511 - val_loss: 1.1706 - val_acc: 0.5937\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.9574 - acc: 0.6620 - val_loss: 1.1497 - val_acc: 0.6025\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.9330 - acc: 0.6712 - val_loss: 1.1959 - val_acc: 0.6019\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.9086 - acc: 0.6775 - val_loss: 1.2131 - val_acc: 0.6112\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.8889 - acc: 0.6850 - val_loss: 1.2402 - val_acc: 0.5890\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.8684 - acc: 0.6958 - val_loss: 1.2509 - val_acc: 0.5926\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.8369 - acc: 0.7046 - val_loss: 1.2074 - val_acc: 0.6043\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.8241 - acc: 0.7115 - val_loss: 1.2949 - val_acc: 0.6052\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.8141 - acc: 0.7119 - val_loss: 1.2444 - val_acc: 0.6016\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.7841 - acc: 0.7239 - val_loss: 1.2852 - val_acc: 0.6087\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.7731 - acc: 0.7262 - val_loss: 1.2884 - val_acc: 0.6028\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.7605 - acc: 0.7326 - val_loss: 1.2875 - val_acc: 0.6117\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.7486 - acc: 0.7399 - val_loss: 1.3960 - val_acc: 0.5998\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.7193 - acc: 0.7497 - val_loss: 1.3135 - val_acc: 0.6030\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.7092 - acc: 0.7538 - val_loss: 1.4403 - val_acc: 0.5894\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.7000 - acc: 0.7560 - val_loss: 1.3458 - val_acc: 0.5988\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.6883 - acc: 0.7604 - val_loss: 1.4820 - val_acc: 0.6061\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.6659 - acc: 0.7720 - val_loss: 1.4483 - val_acc: 0.6199\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.6522 - acc: 0.7730 - val_loss: 1.4436 - val_acc: 0.6062\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6544 - acc: 0.7752 - val_loss: 1.4579 - val_acc: 0.6063\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6493 - acc: 0.7780 - val_loss: 1.4674 - val_acc: 0.6024\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.6190 - acc: 0.7889 - val_loss: 1.5421 - val_acc: 0.6100\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.6210 - acc: 0.7890 - val_loss: 1.5353 - val_acc: 0.6082\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.6043 - acc: 0.7949 - val_loss: 1.4677 - val_acc: 0.6058\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5965 - acc: 0.7951 - val_loss: 1.5559 - val_acc: 0.6011\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5902 - acc: 0.8024 - val_loss: 1.6239 - val_acc: 0.5998\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5839 - acc: 0.8006 - val_loss: 1.5632 - val_acc: 0.6033\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.5659 - acc: 0.8096 - val_loss: 1.5724 - val_acc: 0.6133\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5696 - acc: 0.8084 - val_loss: 1.5864 - val_acc: 0.5957\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5559 - acc: 0.8148 - val_loss: 1.6998 - val_acc: 0.6099\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5362 - acc: 0.8202 - val_loss: 1.6599 - val_acc: 0.6103\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5510 - acc: 0.8172 - val_loss: 1.5943 - val_acc: 0.5908\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5394 - acc: 0.8193 - val_loss: 1.6088 - val_acc: 0.6122\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.5592 - acc: 0.8179 - val_loss: 1.6079 - val_acc: 0.5956\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.5370 - acc: 0.8221 - val_loss: 1.6929 - val_acc: 0.6053\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5195 - acc: 0.8268 - val_loss: 1.6701 - val_acc: 0.6027\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.5032 - acc: 0.8326 - val_loss: 1.7140 - val_acc: 0.6067\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4988 - acc: 0.8355 - val_loss: 1.8260 - val_acc: 0.6000\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.4963 - acc: 0.8407 - val_loss: 1.7697 - val_acc: 0.6004\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.5056 - acc: 0.8359 - val_loss: 1.7743 - val_acc: 0.5975\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5057 - acc: 0.8370 - val_loss: 1.8124 - val_acc: 0.5993\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 0.4863 - acc: 0.8431 - val_loss: 1.7908 - val_acc: 0.6021\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.4878 - acc: 0.8432 - val_loss: 1.8469 - val_acc: 0.6075\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 0.4825 - acc: 0.8466 - val_loss: 1.7047 - val_acc: 0.5951\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2680s 54ms/step - loss: 0.4599 - acc: 0.8537 - val_loss: 1.7947 - val_acc: 0.6050\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4607 - acc: 0.8506 - val_loss: 1.7864 - val_acc: 0.5984\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4640 - acc: 0.8530 - val_loss: 1.7758 - val_acc: 0.6013\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4518 - acc: 0.8570 - val_loss: 1.9298 - val_acc: 0.5918\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4564 - acc: 0.8558 - val_loss: 1.8824 - val_acc: 0.6002\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4578 - acc: 0.8534 - val_loss: 1.9730 - val_acc: 0.5959\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4506 - acc: 0.8571 - val_loss: 1.8886 - val_acc: 0.5957\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4339 - acc: 0.8629 - val_loss: 2.0158 - val_acc: 0.5975\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4656 - acc: 0.8545 - val_loss: 1.9233 - val_acc: 0.6050\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4385 - acc: 0.8625 - val_loss: 1.9096 - val_acc: 0.6022\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4548 - acc: 0.8594 - val_loss: 2.0304 - val_acc: 0.6035\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4750 - acc: 0.8521 - val_loss: 1.9239 - val_acc: 0.5965\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4394 - acc: 0.8618 - val_loss: 1.9778 - val_acc: 0.6072\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4350 - acc: 0.8667 - val_loss: 1.7833 - val_acc: 0.5926\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4323 - acc: 0.8648 - val_loss: 1.9448 - val_acc: 0.5982\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 49s 985us/step - loss: 0.4379 - acc: 0.8658 - val_loss: 2.0512 - val_acc: 0.5996\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 49s 975us/step - loss: 0.4248 - acc: 0.8685 - val_loss: 2.0915 - val_acc: 0.5936\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 49s 986us/step - loss: 0.3952 - acc: 0.8775 - val_loss: 2.0402 - val_acc: 0.6067\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 0.4401 - acc: 0.8666 - val_loss: 2.0085 - val_acc: 0.5998\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 49s 979us/step - loss: 0.4375 - acc: 0.8673 - val_loss: 2.0725 - val_acc: 0.6036\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 49s 976us/step - loss: 0.4032 - acc: 0.8787 - val_loss: 2.1381 - val_acc: 0.5950\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 49s 976us/step - loss: 0.4385 - acc: 0.8686 - val_loss: 2.0900 - val_acc: 0.5997\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4165 - acc: 0.8725 - val_loss: 1.9675 - val_acc: 0.6031\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.4739 - acc: 0.8557 - val_loss: 1.9335 - val_acc: 0.5971\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4350 - acc: 0.8669 - val_loss: 2.0209 - val_acc: 0.6020\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4058 - acc: 0.8781 - val_loss: 2.3155 - val_acc: 0.5945\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4744 - acc: 0.8584 - val_loss: 1.9531 - val_acc: 0.6073\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4168 - acc: 0.8746 - val_loss: 2.2034 - val_acc: 0.6039\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4401 - acc: 0.8691 - val_loss: 2.0594 - val_acc: 0.5991\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.4273 - acc: 0.8721 - val_loss: 2.2716 - val_acc: 0.6086\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.4145 - acc: 0.8750 - val_loss: 2.1954 - val_acc: 0.6046\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.3990 - acc: 0.8803 - val_loss: 2.2881 - val_acc: 0.6031\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.3824 - acc: 0.8874 - val_loss: 2.0770 - val_acc: 0.5672\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.5065 - acc: 0.8492 - val_loss: 2.3142 - val_acc: 0.6045\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4260 - acc: 0.8741 - val_loss: 2.2175 - val_acc: 0.5864\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4479 - acc: 0.8683 - val_loss: 2.2041 - val_acc: 0.5739\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4071 - acc: 0.8773 - val_loss: 2.2946 - val_acc: 0.5935\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4773 - acc: 0.8602 - val_loss: 2.2143 - val_acc: 0.5948\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4257 - acc: 0.8770 - val_loss: 2.2630 - val_acc: 0.5953\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3947 - acc: 0.8848 - val_loss: 2.2805 - val_acc: 0.5970\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.4633 - acc: 0.8634 - val_loss: 2.3241 - val_acc: 0.5998\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4310 - acc: 0.8764 - val_loss: 2.0227 - val_acc: 0.5920\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4289 - acc: 0.8743 - val_loss: 2.3327 - val_acc: 0.5977\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4123 - acc: 0.8805 - val_loss: 2.2828 - val_acc: 0.5963\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.4993 - acc: 0.8577 - val_loss: 2.1528 - val_acc: 0.6030\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.4474 - acc: 0.8692 - val_loss: 2.0674 - val_acc: 0.5943\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4862 - acc: 0.8565 - val_loss: 1.8976 - val_acc: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d7029b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_model.fit(train_images, train_labels, batch_size=64, epochs=100, initial_epoch=0, verbose=1, validation_data=(cv_images, cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dropout_model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(dropout_model, 'dropout_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The best accuracy on the test set is 0.6199 (epoch 27)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
